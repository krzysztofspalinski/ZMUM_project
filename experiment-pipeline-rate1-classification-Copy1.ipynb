{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = './GoogleNews-vectors-negative300.bin.gz' \n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krzysztof/.conda/envs/ml-nlp/lib/python3.7/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/Train.csv', sep=';')\n",
    "test = pd.read_csv('./data/TestX.csv', sep=';')\n",
    "\n",
    "train.opinion = train.opinion.apply(lambda x: x.replace(\"&#039;\", \"'\"))\n",
    "test.opinion = test.opinion.apply(lambda x: x.replace(\"&#039;\", \"'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop_duplicates('opinion').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 30000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a question to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['opinion_length'] = train.opinion.apply(lambda x: len(x))\n",
    "train['capital_counts'] = train.opinion.apply(lambda x: sum(1 for c in x if c.isupper()))\n",
    "train['special_counts'] = train.opinion.apply(lambda x: sum(1 for c in x if c in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~'))\n",
    "train['word_count'] = train.opinion.apply(lambda x: len(str(x).split()))\n",
    "train['unique_word_count'] = train.opinion.apply(lambda x: len(set(str(x).split())))\n",
    "train['mean_word_length'] = train.opinion.apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "train['name_count'] = train.opinion.apply(lambda x: sum(1 for c in x.split() if c[0].isupper()))\n",
    "\n",
    "test['opinion_length'] = test.opinion.apply(lambda x: len(x))\n",
    "test['capital_counts'] = test.opinion.apply(lambda x: sum(1 for c in x if c.isupper()))\n",
    "test['special_counts'] = test.opinion.apply(lambda x: sum(1 for c in x if c in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~'))\n",
    "test['word_count'] = test.opinion.apply(lambda x: len(str(x).split()))\n",
    "test['unique_word_count'] = test.opinion.apply(lambda x: len(set(str(x).split())))\n",
    "test['mean_word_length'] = test.opinion.apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test['name_count'] = test.opinion.apply(lambda x: sum(1 for c in x.split() if c[0].isupper()))\n",
    "\n",
    "meta_features = ['opinion_length', 'capital_counts', 'special_counts', 'word_count', 'unique_word_count', 'mean_word_length', 'name_count']\n",
    "\n",
    "for feature in meta_features:\n",
    "    max_value = train[feature].max()\n",
    "    train[feature] = train[feature] / max_value\n",
    "    test[feature] = test[feature] / max_value\n",
    "\n",
    "condition_features = list(train.condition.value_counts().index)[:60]\n",
    "for condition_feature in condition_features:\n",
    "    train['condition_' + condition_feature] = (train.condition == condition_feature).astype(int)\n",
    "    test['condition_' + condition_feature] = (test.condition == condition_feature).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator \n",
    "import re\n",
    "\n",
    "\n",
    "def check_coverage(vocab,embeddings_index):\n",
    "    a = {}\n",
    "    oov = {}\n",
    "    k = 0\n",
    "    i = 0\n",
    "    for word in tqdm(vocab):\n",
    "        try:\n",
    "            a[word] = embeddings_index[word]\n",
    "            k += vocab[word]\n",
    "        except:\n",
    "\n",
    "            oov[word] = vocab[word]\n",
    "            i += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
    "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return sorted_x\n",
    "\n",
    "\n",
    "def build_vocab(sentences, verbose =  True):\n",
    "    \"\"\"\n",
    "    :param sentences: list of list of words\n",
    "    :return: dictionary of words and their count\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in \"/-'\":\n",
    "        x = x.replace(punct, ' ')\n",
    "    for punct in '&':\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’':\n",
    "        x = x.replace(punct, '')\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "\n",
    "mispell_dict = {'colour':'color',\n",
    "                'centre':'center',\n",
    "                'didnt':'did not',\n",
    "                'doesnt':'does not',\n",
    "                'isnt':'is not',\n",
    "                'shouldnt':'should not',\n",
    "                'favourite':'favorite',\n",
    "                'travelling':'traveling',\n",
    "                'counselling':'counseling',\n",
    "                'theatre':'theater',\n",
    "                'cancelled':'canceled',\n",
    "                'labour':'labor',\n",
    "                'organisation':'organization',\n",
    "                'wwii':'world war 2',\n",
    "                'citicise':'criticize',\n",
    "                'instagram': 'social medium',\n",
    "                'whatsapp': 'social medium',\n",
    "                'snapchat': 'social medium'}\n",
    "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "\n",
    "    return mispellings_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107590/107590 [00:00<00:00, 163403.06it/s]\n",
      "100%|██████████| 107590/107590 [00:01<00:00, 74799.58it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = train[\"opinion\"].progress_apply(lambda x: x.split()).values\n",
    "vocab = build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188722/188722 [00:00<00:00, 548854.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 20.39% of vocab\n",
      "Found embeddings for  77.62% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab, word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['opinion'] = train['opinion'].str.replace('\"', '')\n",
    "train['opinion'] = train['opinion'].str.replace(',', '')\n",
    "train['opinion'] = train['opinion'].str.replace('.', '')\n",
    "train['opinion'] = train['opinion'].str.replace('!', '')\n",
    "train['opinion'] = train['opinion'].str.replace(':', '')\n",
    "train['opinion'] = train['opinion'].str.replace('&#039;ve', ' have')\n",
    "train['opinion'] = train['opinion'].str.replace('&#039;s', ' is')\n",
    "train['opinion'] = train['opinion'].str.replace('&#039;t', ' not')\n",
    "train['opinion'] = train['opinion'].str.replace('&#039;m', ' am')\n",
    "train['opinion'] = train['opinion'].str.replace('&#039;ll', '')\n",
    "train['opinion'] = train['opinion'].str.replace('rsquot', '')\n",
    "train['opinion'] = train['opinion'].str.replace('rsquom', '')\n",
    "train['opinion'] = train['opinion'].str.replace('rsquos', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['opinion'] = test['opinion'].str.replace('\"', '')\n",
    "test['opinion'] = test['opinion'].str.replace(',', '')\n",
    "test['opinion'] = test['opinion'].str.replace('.', '')\n",
    "test['opinion'] = test['opinion'].str.replace('!', '')\n",
    "test['opinion'] = test['opinion'].str.replace(':', '')\n",
    "test['opinion'] = test['opinion'].str.replace('&#039;ve', ' have')\n",
    "test['opinion'] = test['opinion'].str.replace('&#039;s', ' is')\n",
    "test['opinion'] = test['opinion'].str.replace('&#039;t', ' not')\n",
    "test['opinion'] = test['opinion'].str.replace('&#039;m', ' am')\n",
    "test['opinion'] = test['opinion'].str.replace('&#039;ll', '')\n",
    "test['opinion'] = test['opinion'].str.replace('rsquot', '')\n",
    "test['opinion'] = test['opinion'].str.replace('rsquom', '')\n",
    "test['opinion'] = test['opinion'].str.replace('rsquos', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107590/107590 [00:00<00:00, 116579.87it/s]\n",
      "100%|██████████| 107590/107590 [00:03<00:00, 31106.23it/s]\n",
      "100%|██████████| 107590/107590 [00:01<00:00, 81952.82it/s]\n"
     ]
    }
   ],
   "source": [
    "train[\"opinion\"] = train[\"opinion\"].progress_apply(lambda x: clean_text(x))\n",
    "train[\"opinion\"] = train[\"opinion\"].progress_apply(lambda x: clean_numbers(x))\n",
    "train[\"opinion\"] = train[\"opinion\"].progress_apply(lambda x: replace_typical_misspell(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:00<00:00, 114485.99it/s]\n",
      "100%|██████████| 50000/50000 [00:01<00:00, 32472.32it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 81643.02it/s]\n"
     ]
    }
   ],
   "source": [
    "test[\"opinion\"] = test[\"opinion\"].progress_apply(lambda x: clean_text(x))\n",
    "test[\"opinion\"] = test[\"opinion\"].progress_apply(lambda x: clean_numbers(x))\n",
    "test[\"opinion\"] = test[\"opinion\"].progress_apply(lambda x: replace_typical_misspell(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107590/107590 [00:01<00:00, 64449.80it/s]\n",
      "100%|██████████| 107590/107590 [00:00<00:00, 108162.39it/s]\n",
      "100%|██████████| 107590/107590 [00:01<00:00, 95896.34it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = train[\"opinion\"].progress_apply(lambda x: x.split())\n",
    "to_remove = ['a','to','of','and']\n",
    "sentences = [[word for word in sentence if not word in to_remove] for sentence in tqdm(sentences)]\n",
    "vocab = build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74690/74690 [00:00<00:00, 524081.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 57.90% of vocab\n",
      "Found embeddings for  99.12% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Nexplanon', 1254),\n",
       " ('Sprintec', 824),\n",
       " ('nexplanon', 744),\n",
       " ('rsquot', 673),\n",
       " ('Belviq', 585),\n",
       " ('mirena', 445),\n",
       " ('rsquom', 442),\n",
       " ('skyla', 399),\n",
       " ('rsquos', 382),\n",
       " ('implanon', 366)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_oov = [i for i, j in oov[:40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for oov_word in top_oov:\n",
    "    train['oov_' + oov_word] = train.opinion.apply(lambda x: oov_word in x)\n",
    "    test['oov_' + oov_word] = test.opinion.apply(lambda x: oov_word in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = meta_features + ['condition_' + i for i in condition_features] + ['oov_' + i for i in top_oov]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(train, test_size=0.08, random_state=42)\n",
    "\n",
    "X_train_meta = np.array(train_df.loc[:, features]).astype(np.float32)\n",
    "X_val_meta = np.array(val_df.loc[:, features]).astype(np.float32)\n",
    "X_test_meta = np.array(test.loc[:, features]).astype(np.float32)\n",
    "\n",
    "X_train = train_df.opinion.values\n",
    "X_val = val_df.opinion.values\n",
    "X_test = test.opinion.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words = max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(list(X_train))\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_val = pad_sequences(X_val, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['rate1'].values\n",
    "y_val = val_df['rate1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, GlobalMaxPool1D, Bidirectional, LSTM, Embedding, Input, Concatenate, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((max_features, embed_size))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = word2vec.get_vector(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            embedding_vector = None\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['high' 'low' 'medium']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)\n",
    "\n",
    "print(le.classes_)\n",
    "\n",
    "y_train = le.transform(y_train)\n",
    "y_val = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_models_cls import model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Model 1, iteration 0\n",
      "Train on 94032 samples, validate on 4950 samples\n",
      "Epoch 1/20\n",
      "94032/94032 [==============================] - 29s 303us/sample - loss: 0.7341 - accuracy: 0.6904 - val_loss: 0.6430 - val_accuracy: 0.7295\n",
      "Epoch 2/20\n",
      "94032/94032 [==============================] - 25s 268us/sample - loss: 0.5881 - accuracy: 0.7561 - val_loss: 0.6109 - val_accuracy: 0.7386\n",
      "Epoch 3/20\n",
      "94032/94032 [==============================] - 26s 272us/sample - loss: 0.5382 - accuracy: 0.7773 - val_loss: 0.5928 - val_accuracy: 0.7507\n",
      "Epoch 4/20\n",
      "94032/94032 [==============================] - 26s 273us/sample - loss: 0.4989 - accuracy: 0.7954 - val_loss: 0.5892 - val_accuracy: 0.7477\n",
      "Epoch 5/20\n",
      "94032/94032 [==============================] - 26s 274us/sample - loss: 0.4631 - accuracy: 0.8111 - val_loss: 0.6175 - val_accuracy: 0.7349\n",
      "Epoch 6/20\n",
      "94032/94032 [==============================] - 26s 274us/sample - loss: 0.4217 - accuracy: 0.8291 - val_loss: 0.6320 - val_accuracy: 0.7428\n",
      "Epoch 7/20\n",
      "94032/94032 [==============================] - 26s 272us/sample - loss: 0.3841 - accuracy: 0.8464 - val_loss: 0.6786 - val_accuracy: 0.7404\n",
      "Epoch 8/20\n",
      "94032/94032 [==============================] - 26s 272us/sample - loss: 0.3437 - accuracy: 0.8623 - val_loss: 0.7268 - val_accuracy: 0.7240\n",
      "Epoch 9/20\n",
      "94032/94032 [==============================] - 26s 272us/sample - loss: 0.3073 - accuracy: 0.8789 - val_loss: 0.8003 - val_accuracy: 0.7406\n"
     ]
    }
   ],
   "source": [
    "#for i in range(10):\n",
    "i = 0   \n",
    "X_train_tmp, X_val_tmp, y_train_tmp, y_val_tmp = train_test_split(\n",
    "    np.concatenate((X_train, X_train_meta), axis=1), \n",
    "    y_train, \n",
    "    test_size=0.05)\n",
    "\n",
    "X_train_tmp, X_train_tmp_meta = X_train_tmp[:,:100], X_train_tmp[:,100:]\n",
    "X_val_tmp, X_val_tmp_meta = X_val_tmp[:,:100], X_val_tmp[:,100:]\n",
    "\n",
    "\n",
    "model = model_1.get_model(embedding_matrix, maxlen, max_features, embed_size, len(features))\n",
    "adam = tf.keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "print(\"##################################################\")\n",
    "print(f'Model 1, iteration {i}')\n",
    "\n",
    "callback_earlystop = tf.keras.callbacks.EarlyStopping(patience=5,\n",
    "                                           monitor='val_loss',\n",
    "                                           mode='auto',\n",
    "                                           restore_best_weights=True)\n",
    "\n",
    "\n",
    "model.fit([X_train_tmp, X_train_tmp_meta], y_train_tmp, epochs = 20, batch_size=256,\n",
    "          callbacks=[callback_earlystop], validation_data=([X_val_tmp, X_val_tmp_meta], y_val_tmp))\n",
    "\n",
    "y_hat_val = model.predict([X_val, X_val_meta]).astype('float32')\n",
    "y_hat_val.tofile(f'./results/Model_1_{i}_val_cls')\n",
    "\n",
    "y_hat_test = model.predict([X_test, X_test_meta]).astype('float32')\n",
    "y_hat_test.tofile(f'./results/Model_1_{i}_test_cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_hat_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([32207.,     0.,     0.,     0.,     0., 10893.,     0.,     0.,\n",
       "            0.,  6900.]),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.argmax(y_hat_test, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_hat_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_hat_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.argmax(y_hat_val, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_hat_val, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_h = np.zeros_like(y_hat_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    y_hat_tmp = np.fromfile(f'./results/Model_1_{i}_val_cls', dtype='float32').reshape(-1, 3)\n",
    "    \n",
    "    y_hat_tmp_cat = to_categorical(np.argmax(y_hat_tmp, axis=1))\n",
    "    \n",
    "    y_h = y_h + y_hat_tmp_cat\n",
    "\n",
    "y_h = y_h + np.random.normal(size=y_h.shape)/1e4    \n",
    "\n",
    "accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_h, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_tmp = np.fromfile(f'./results/Model_1_9_val_cls', dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_tmp.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_tmp = np.fromfile(f'./results/Model_1_0_val_cls', dtype='float32').reshape(-1, 3)\n",
    "np.random.normal(size=y_hat_tmp.shape)/1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-nlp)",
   "language": "python",
   "name": "ml-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
