{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = './GoogleNews-vectors-negative300.bin.gz' \n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krzysztof/.conda/envs/ml-nlp/lib/python3.7/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/Train.csv', sep=';')\n",
    "test = pd.read_csv('./data/TestX.csv', sep=';')\n",
    "\n",
    "train.opinion = train.opinion.apply(lambda x: x.replace(\"&#039;\", \"'\"))\n",
    "test.opinion = test.opinion.apply(lambda x: x.replace(\"&#039;\", \"'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop_duplicates('opinion').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 30000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a question to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['opinion_length'] = train.opinion.apply(lambda x: len(x))\n",
    "train['capital_counts'] = train.opinion.apply(lambda x: sum(1 for c in x if c.isupper()))\n",
    "train['special_counts'] = train.opinion.apply(lambda x: sum(1 for c in x if c in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~'))\n",
    "train['word_count'] = train.opinion.apply(lambda x: len(str(x).split()))\n",
    "train['unique_word_count'] = train.opinion.apply(lambda x: len(set(str(x).split())))\n",
    "train['mean_word_length'] = train.opinion.apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "train['name_count'] = train.opinion.apply(lambda x: sum(1 for c in x.split() if c[0].isupper()))\n",
    "\n",
    "test['opinion_length'] = test.opinion.apply(lambda x: len(x))\n",
    "test['capital_counts'] = test.opinion.apply(lambda x: sum(1 for c in x if c.isupper()))\n",
    "test['special_counts'] = test.opinion.apply(lambda x: sum(1 for c in x if c in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~'))\n",
    "test['word_count'] = test.opinion.apply(lambda x: len(str(x).split()))\n",
    "test['unique_word_count'] = test.opinion.apply(lambda x: len(set(str(x).split())))\n",
    "test['mean_word_length'] = test.opinion.apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test['name_count'] = test.opinion.apply(lambda x: sum(1 for c in x.split() if c[0].isupper()))\n",
    "\n",
    "meta_features = ['opinion_length', 'capital_counts', 'special_counts', 'word_count', 'unique_word_count', 'mean_word_length', 'name_count']\n",
    "\n",
    "for feature in meta_features:\n",
    "    train[feature] = train[feature] / train[feature].max()\n",
    "    test[feature] = test[feature] / train[feature].max()\n",
    "\n",
    "condition_features = list(train.condition.value_counts().index)[:60]\n",
    "for condition_feature in condition_features:\n",
    "    train['condition_' + condition_feature] = (train.condition == condition_feature).astype(int)\n",
    "    test['condition_' + condition_feature] = (test.condition == condition_feature).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator \n",
    "import re\n",
    "\n",
    "\n",
    "def check_coverage(vocab,embeddings_index):\n",
    "    a = {}\n",
    "    oov = {}\n",
    "    k = 0\n",
    "    i = 0\n",
    "    for word in tqdm(vocab):\n",
    "        try:\n",
    "            a[word] = embeddings_index[word]\n",
    "            k += vocab[word]\n",
    "        except:\n",
    "\n",
    "            oov[word] = vocab[word]\n",
    "            i += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
    "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return sorted_x\n",
    "\n",
    "\n",
    "def build_vocab(sentences, verbose =  True):\n",
    "    \"\"\"\n",
    "    :param sentences: list of list of words\n",
    "    :return: dictionary of words and their count\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in \"/-'\":\n",
    "        x = x.replace(punct, ' ')\n",
    "    for punct in '&':\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’':\n",
    "        x = x.replace(punct, '')\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "\n",
    "mispell_dict = {'colour':'color',\n",
    "                'centre':'center',\n",
    "                'didnt':'did not',\n",
    "                'doesnt':'does not',\n",
    "                'isnt':'is not',\n",
    "                'shouldnt':'should not',\n",
    "                'favourite':'favorite',\n",
    "                'travelling':'traveling',\n",
    "                'counselling':'counseling',\n",
    "                'theatre':'theater',\n",
    "                'cancelled':'canceled',\n",
    "                'labour':'labor',\n",
    "                'organisation':'organization',\n",
    "                'wwii':'world war 2',\n",
    "                'citicise':'criticize',\n",
    "                'instagram': 'social medium',\n",
    "                'whatsapp': 'social medium',\n",
    "                'snapchat': 'social medium'}\n",
    "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "\n",
    "    return mispellings_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107590/107590 [00:00<00:00, 142432.49it/s]\n",
      "100%|██████████| 107590/107590 [00:01<00:00, 59528.02it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = train[\"opinion\"].progress_apply(lambda x: x.split()).values\n",
    "vocab = build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188722/188722 [00:00<00:00, 539746.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 20.39% of vocab\n",
      "Found embeddings for  77.62% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab, word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['opinion'] = train['opinion'].str.replace('\"', '')\n",
    "train['opinion'] = train['opinion'].str.replace(',', '')\n",
    "train['opinion'] = train['opinion'].str.replace('.', '')\n",
    "train['opinion'] = train['opinion'].str.replace('!', '')\n",
    "train['opinion'] = train['opinion'].str.replace(':', '')\n",
    "train['opinion'] = train['opinion'].str.replace('&#039;ve', ' have')\n",
    "train['opinion'] = train['opinion'].str.replace('&#039;s', ' is')\n",
    "train['opinion'] = train['opinion'].str.replace('&#039;t', ' not')\n",
    "train['opinion'] = train['opinion'].str.replace('&#039;m', ' am')\n",
    "train['opinion'] = train['opinion'].str.replace('&#039;ll', '')\n",
    "train['opinion'] = train['opinion'].str.replace('rsquot', '')\n",
    "train['opinion'] = train['opinion'].str.replace('rsquom', '')\n",
    "train['opinion'] = train['opinion'].str.replace('rsquos', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['opinion'] = test['opinion'].str.replace('\"', '')\n",
    "test['opinion'] = test['opinion'].str.replace(',', '')\n",
    "test['opinion'] = test['opinion'].str.replace('.', '')\n",
    "test['opinion'] = test['opinion'].str.replace('!', '')\n",
    "test['opinion'] = test['opinion'].str.replace(':', '')\n",
    "test['opinion'] = test['opinion'].str.replace('&#039;ve', ' have')\n",
    "test['opinion'] = test['opinion'].str.replace('&#039;s', ' is')\n",
    "test['opinion'] = test['opinion'].str.replace('&#039;t', ' not')\n",
    "test['opinion'] = test['opinion'].str.replace('&#039;m', ' am')\n",
    "test['opinion'] = test['opinion'].str.replace('&#039;ll', '')\n",
    "test['opinion'] = test['opinion'].str.replace('rsquot', '')\n",
    "test['opinion'] = test['opinion'].str.replace('rsquom', '')\n",
    "test['opinion'] = test['opinion'].str.replace('rsquos', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107518/107518 [00:00<00:00, 114417.47it/s]\n",
      "100%|██████████| 107518/107518 [00:03<00:00, 29215.82it/s]\n",
      "100%|██████████| 107518/107518 [00:01<00:00, 73223.89it/s]\n"
     ]
    }
   ],
   "source": [
    "train[\"opinion\"] = train[\"opinion\"].progress_apply(lambda x: clean_text(x))\n",
    "train[\"opinion\"] = train[\"opinion\"].progress_apply(lambda x: clean_numbers(x))\n",
    "train[\"opinion\"] = train[\"opinion\"].progress_apply(lambda x: replace_typical_misspell(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45233/45233 [00:00<00:00, 106797.32it/s]\n",
      "100%|██████████| 45233/45233 [00:01<00:00, 27666.73it/s]\n",
      "100%|██████████| 45233/45233 [00:00<00:00, 71488.30it/s]\n"
     ]
    }
   ],
   "source": [
    "test[\"opinion\"] = test[\"opinion\"].progress_apply(lambda x: clean_text(x))\n",
    "test[\"opinion\"] = test[\"opinion\"].progress_apply(lambda x: clean_numbers(x))\n",
    "test[\"opinion\"] = test[\"opinion\"].progress_apply(lambda x: replace_typical_misspell(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107518/107518 [00:00<00:00, 153636.01it/s]\n",
      "100%|██████████| 107518/107518 [00:00<00:00, 116380.99it/s]\n",
      "100%|██████████| 107518/107518 [00:01<00:00, 89598.69it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = train[\"opinion\"].progress_apply(lambda x: x.split())\n",
    "to_remove = ['a','to','of','and']\n",
    "sentences = [[word for word in sentence if not word in to_remove] for sentence in tqdm(sentences)]\n",
    "vocab = build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74690/74690 [00:00<00:00, 501960.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 57.90% of vocab\n",
      "Found embeddings for  99.12% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Nexplanon', 1254),\n",
       " ('Sprintec', 824),\n",
       " ('nexplanon', 744),\n",
       " ('rsquot', 673),\n",
       " ('Belviq', 585),\n",
       " ('mirena', 445),\n",
       " ('rsquom', 442),\n",
       " ('skyla', 399),\n",
       " ('rsquos', 382),\n",
       " ('implanon', 366)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_oov = [i for i, j in oov[:40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for oov_word in top_oov:\n",
    "    train['oov_' + oov_word] = train.opinion.apply(lambda x: oov_word in x)\n",
    "    test['oov_' + oov_word] = test.opinion.apply(lambda x: oov_word in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = meta_features + ['condition_' + i for i in condition_features] + ['oov_' + i for i in top_oov]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(train, test_size=0.08, random_state=42)\n",
    "\n",
    "X_train_meta = np.array(train_df.loc[:, features]).astype(np.float32)\n",
    "X_val_meta = np.array(val_df.loc[:, features]).astype(np.float32)\n",
    "X_test_meta = np.array(test.loc[:, features]).astype(np.float32)\n",
    "\n",
    "X_train = train_df.opinion.values\n",
    "X_val = val_df.opinion.values\n",
    "X_test = test.opinion.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words = max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(list(X_train))\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_val = pad_sequences(X_val, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['rate1'].values\n",
    "y_val = val_df['rate1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, GlobalMaxPool1D, Bidirectional, LSTM, Embedding, Input, Concatenate, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((max_features, embed_size))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = word2vec.get_vector(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            embedding_vector = None\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['high' 'low' 'medium']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)\n",
    "\n",
    "print(le.classes_)\n",
    "\n",
    "y_train = le.transform(y_train)\n",
    "y_val = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_models_cls import model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Model 1, iteration 0\n",
      "Train on 93970 samples, validate on 4946 samples\n",
      "Epoch 1/20\n",
      "93970/93970 [==============================] - 26s 280us/sample - loss: 0.7391 - accuracy: 0.6895 - val_loss: 0.6299 - val_accuracy: 0.7347\n",
      "Epoch 2/20\n",
      "93970/93970 [==============================] - 25s 261us/sample - loss: 0.5962 - accuracy: 0.7515 - val_loss: 0.5779 - val_accuracy: 0.7594\n",
      "Epoch 3/20\n",
      "93970/93970 [==============================] - 25s 264us/sample - loss: 0.5460 - accuracy: 0.7739 - val_loss: 0.5700 - val_accuracy: 0.7630\n",
      "Epoch 4/20\n",
      "93970/93970 [==============================] - 25s 267us/sample - loss: 0.5091 - accuracy: 0.7902 - val_loss: 0.5892 - val_accuracy: 0.7596\n",
      "Epoch 5/20\n",
      "93970/93970 [==============================] - 25s 265us/sample - loss: 0.4716 - accuracy: 0.8069 - val_loss: 0.6774 - val_accuracy: 0.7180\n",
      "Epoch 6/20\n",
      "93970/93970 [==============================] - 26s 278us/sample - loss: 0.4344 - accuracy: 0.8238 - val_loss: 0.6493 - val_accuracy: 0.7473\n",
      "Epoch 7/20\n",
      "93970/93970 [==============================] - 26s 275us/sample - loss: 0.3951 - accuracy: 0.8407 - val_loss: 0.6150 - val_accuracy: 0.7576\n",
      "Epoch 8/20\n",
      "93970/93970 [==============================] - 26s 273us/sample - loss: 0.3548 - accuracy: 0.8584 - val_loss: 0.6581 - val_accuracy: 0.7509\n",
      "##################################################\n",
      "Model 1, iteration 1\n",
      "Train on 93970 samples, validate on 4946 samples\n",
      "Epoch 1/20\n",
      "93970/93970 [==============================] - 27s 287us/sample - loss: 0.7377 - accuracy: 0.6893 - val_loss: 0.6388 - val_accuracy: 0.7359\n",
      "Epoch 2/20\n",
      "93970/93970 [==============================] - 25s 268us/sample - loss: 0.5956 - accuracy: 0.7501 - val_loss: 0.5798 - val_accuracy: 0.7651\n",
      "Epoch 3/20\n",
      "93970/93970 [==============================] - 25s 261us/sample - loss: 0.5444 - accuracy: 0.7748 - val_loss: 0.6082 - val_accuracy: 0.7529\n",
      "Epoch 4/20\n",
      "93970/93970 [==============================] - 25s 267us/sample - loss: 0.5104 - accuracy: 0.7890 - val_loss: 0.5572 - val_accuracy: 0.7683\n",
      "Epoch 5/20\n",
      "93970/93970 [==============================] - 25s 267us/sample - loss: 0.4713 - accuracy: 0.8064 - val_loss: 0.6271 - val_accuracy: 0.7489\n",
      "Epoch 6/20\n",
      "93970/93970 [==============================] - 25s 267us/sample - loss: 0.4373 - accuracy: 0.8211 - val_loss: 0.6245 - val_accuracy: 0.7541\n",
      "Epoch 7/20\n",
      "93970/93970 [==============================] - 25s 267us/sample - loss: 0.3983 - accuracy: 0.8390 - val_loss: 0.6109 - val_accuracy: 0.7511\n",
      "Epoch 8/20\n",
      "93970/93970 [==============================] - 25s 267us/sample - loss: 0.3544 - accuracy: 0.8584 - val_loss: 0.6402 - val_accuracy: 0.7517\n",
      "Epoch 9/20\n",
      "93970/93970 [==============================] - 25s 270us/sample - loss: 0.3117 - accuracy: 0.8783 - val_loss: 0.7064 - val_accuracy: 0.7495\n",
      "##################################################\n",
      "Model 1, iteration 2\n",
      "Train on 93970 samples, validate on 4946 samples\n",
      "Epoch 1/20\n",
      "93970/93970 [==============================] - 25s 271us/sample - loss: 0.7361 - accuracy: 0.6890 - val_loss: 0.6144 - val_accuracy: 0.7414\n",
      "Epoch 2/20\n",
      "93970/93970 [==============================] - 25s 269us/sample - loss: 0.5943 - accuracy: 0.7504 - val_loss: 0.5718 - val_accuracy: 0.7616\n",
      "Epoch 3/20\n",
      "93970/93970 [==============================] - 25s 262us/sample - loss: 0.5422 - accuracy: 0.7743 - val_loss: 0.5714 - val_accuracy: 0.7683\n",
      "Epoch 4/20\n",
      "93970/93970 [==============================] - 25s 264us/sample - loss: 0.5058 - accuracy: 0.7898 - val_loss: 0.5578 - val_accuracy: 0.7711\n",
      "Epoch 5/20\n",
      "93970/93970 [==============================] - 25s 262us/sample - loss: 0.4699 - accuracy: 0.8068 - val_loss: 0.6060 - val_accuracy: 0.7572\n",
      "Epoch 6/20\n",
      "93970/93970 [==============================] - 24s 259us/sample - loss: 0.4297 - accuracy: 0.8231 - val_loss: 0.6002 - val_accuracy: 0.7537\n",
      "Epoch 7/20\n",
      "93970/93970 [==============================] - 24s 260us/sample - loss: 0.3947 - accuracy: 0.8381 - val_loss: 0.6027 - val_accuracy: 0.7598\n",
      "Epoch 8/20\n",
      "93970/93970 [==============================] - 24s 260us/sample - loss: 0.3517 - accuracy: 0.8586 - val_loss: 0.7018 - val_accuracy: 0.7661\n",
      "Epoch 9/20\n",
      "93970/93970 [==============================] - 24s 252us/sample - loss: 0.3104 - accuracy: 0.8767 - val_loss: 0.7106 - val_accuracy: 0.7483\n",
      "##################################################\n",
      "Model 1, iteration 3\n",
      "Train on 93970 samples, validate on 4946 samples\n",
      "Epoch 1/20\n",
      "93970/93970 [==============================] - 27s 288us/sample - loss: 0.7167 - accuracy: 0.6964 - val_loss: 0.6583 - val_accuracy: 0.7281\n",
      "Epoch 2/20\n",
      "93970/93970 [==============================] - 25s 267us/sample - loss: 0.5856 - accuracy: 0.7554 - val_loss: 0.5886 - val_accuracy: 0.7618\n",
      "Epoch 3/20\n",
      "93970/93970 [==============================] - 25s 269us/sample - loss: 0.5402 - accuracy: 0.7768 - val_loss: 0.5803 - val_accuracy: 0.7643\n",
      "Epoch 4/20\n",
      "93970/93970 [==============================] - 25s 267us/sample - loss: 0.5018 - accuracy: 0.7923 - val_loss: 0.5858 - val_accuracy: 0.7541\n",
      "Epoch 5/20\n",
      "93970/93970 [==============================] - 25s 271us/sample - loss: 0.4634 - accuracy: 0.8094 - val_loss: 0.5915 - val_accuracy: 0.7653\n",
      "Epoch 6/20\n",
      "93970/93970 [==============================] - 25s 267us/sample - loss: 0.4243 - accuracy: 0.8266 - val_loss: 0.6434 - val_accuracy: 0.7347\n",
      "Epoch 7/20\n",
      "93970/93970 [==============================] - 25s 267us/sample - loss: 0.3876 - accuracy: 0.8419 - val_loss: 0.6579 - val_accuracy: 0.7398\n",
      "Epoch 8/20\n",
      "93970/93970 [==============================] - 25s 269us/sample - loss: 0.3413 - accuracy: 0.8621 - val_loss: 0.7135 - val_accuracy: 0.7382\n",
      "##################################################\n",
      "Model 1, iteration 4\n",
      "Train on 93970 samples, validate on 4946 samples\n",
      "Epoch 1/20\n",
      "93970/93970 [==============================] - 27s 288us/sample - loss: 0.7217 - accuracy: 0.6950 - val_loss: 0.6273 - val_accuracy: 0.7359\n",
      "Epoch 2/20\n",
      "93970/93970 [==============================] - 24s 258us/sample - loss: 0.5886 - accuracy: 0.7537 - val_loss: 0.6165 - val_accuracy: 0.7479\n",
      "Epoch 3/20\n",
      "93970/93970 [==============================] - 25s 263us/sample - loss: 0.5408 - accuracy: 0.7752 - val_loss: 0.6156 - val_accuracy: 0.7426\n",
      "Epoch 4/20\n",
      "93970/93970 [==============================] - 24s 256us/sample - loss: 0.5008 - accuracy: 0.7930 - val_loss: 0.5917 - val_accuracy: 0.7608\n",
      "Epoch 5/20\n",
      "93970/93970 [==============================] - 24s 251us/sample - loss: 0.4660 - accuracy: 0.8079 - val_loss: 0.6105 - val_accuracy: 0.7541\n",
      "Epoch 6/20\n",
      "93970/93970 [==============================] - 24s 251us/sample - loss: 0.4292 - accuracy: 0.8243 - val_loss: 0.6600 - val_accuracy: 0.7566\n",
      "Epoch 7/20\n",
      "93970/93970 [==============================] - 23s 248us/sample - loss: 0.3849 - accuracy: 0.8430 - val_loss: 0.6984 - val_accuracy: 0.7147\n",
      "Epoch 8/20\n",
      "93970/93970 [==============================] - 23s 246us/sample - loss: 0.3480 - accuracy: 0.8598 - val_loss: 0.6809 - val_accuracy: 0.7408\n",
      "Epoch 9/20\n",
      "93970/93970 [==============================] - 24s 253us/sample - loss: 0.3040 - accuracy: 0.8784 - val_loss: 0.8168 - val_accuracy: 0.7412\n",
      "##################################################\n",
      "Model 1, iteration 5\n",
      "Train on 93970 samples, validate on 4946 samples\n",
      "Epoch 1/20\n",
      "93970/93970 [==============================] - 27s 282us/sample - loss: 0.7241 - accuracy: 0.6940 - val_loss: 0.6546 - val_accuracy: 0.7159\n",
      "Epoch 2/20\n",
      "93970/93970 [==============================] - 26s 279us/sample - loss: 0.5879 - accuracy: 0.7548 - val_loss: 0.6690 - val_accuracy: 0.7266\n",
      "Epoch 3/20\n",
      "93970/93970 [==============================] - 26s 280us/sample - loss: 0.5407 - accuracy: 0.7769 - val_loss: 0.5848 - val_accuracy: 0.7529\n",
      "Epoch 4/20\n",
      "93970/93970 [==============================] - 26s 280us/sample - loss: 0.4993 - accuracy: 0.7940 - val_loss: 0.6082 - val_accuracy: 0.7442\n",
      "Epoch 5/20\n",
      "93970/93970 [==============================] - 26s 280us/sample - loss: 0.4662 - accuracy: 0.8091 - val_loss: 0.6195 - val_accuracy: 0.7485\n",
      "Epoch 6/20\n",
      "93970/93970 [==============================] - 26s 280us/sample - loss: 0.4295 - accuracy: 0.8250 - val_loss: 0.6490 - val_accuracy: 0.7398\n",
      "Epoch 7/20\n",
      "93970/93970 [==============================] - 26s 279us/sample - loss: 0.3896 - accuracy: 0.8418 - val_loss: 0.7286 - val_accuracy: 0.7424\n",
      "Epoch 8/20\n",
      "93970/93970 [==============================] - 26s 280us/sample - loss: 0.3564 - accuracy: 0.8569 - val_loss: 0.7383 - val_accuracy: 0.7351\n",
      "##################################################\n",
      "Model 1, iteration 6\n",
      "Train on 93970 samples, validate on 4946 samples\n",
      "Epoch 1/20\n",
      "93970/93970 [==============================] - 28s 301us/sample - loss: 0.7349 - accuracy: 0.6908 - val_loss: 0.7244 - val_accuracy: 0.6951\n",
      "Epoch 2/20\n",
      "93970/93970 [==============================] - 26s 279us/sample - loss: 0.5937 - accuracy: 0.7516 - val_loss: 0.5917 - val_accuracy: 0.7543\n",
      "Epoch 3/20\n",
      "93970/93970 [==============================] - 26s 280us/sample - loss: 0.5438 - accuracy: 0.7743 - val_loss: 0.5849 - val_accuracy: 0.7638\n",
      "Epoch 4/20\n",
      "93970/93970 [==============================] - 26s 280us/sample - loss: 0.5061 - accuracy: 0.7898 - val_loss: 0.5738 - val_accuracy: 0.7653\n",
      "Epoch 5/20\n",
      "93970/93970 [==============================] - 26s 273us/sample - loss: 0.4702 - accuracy: 0.8061 - val_loss: 0.5886 - val_accuracy: 0.7641\n",
      "Epoch 6/20\n",
      "93970/93970 [==============================] - 24s 259us/sample - loss: 0.4310 - accuracy: 0.8242 - val_loss: 0.6298 - val_accuracy: 0.7390\n",
      "Epoch 7/20\n",
      "93970/93970 [==============================] - 26s 278us/sample - loss: 0.3951 - accuracy: 0.8402 - val_loss: 0.6113 - val_accuracy: 0.7426\n",
      "Epoch 8/20\n",
      "93970/93970 [==============================] - 26s 281us/sample - loss: 0.3521 - accuracy: 0.8588 - val_loss: 0.7548 - val_accuracy: 0.7521\n",
      "Epoch 9/20\n",
      "93970/93970 [==============================] - 27s 286us/sample - loss: 0.3121 - accuracy: 0.8759 - val_loss: 0.7266 - val_accuracy: 0.7386\n",
      "##################################################\n",
      "Model 1, iteration 7\n",
      "Train on 93970 samples, validate on 4946 samples\n",
      "Epoch 1/20\n",
      "93970/93970 [==============================] - 29s 310us/sample - loss: 0.7338 - accuracy: 0.6900 - val_loss: 0.6549 - val_accuracy: 0.7317\n",
      "Epoch 2/20\n",
      "93970/93970 [==============================] - 27s 288us/sample - loss: 0.5895 - accuracy: 0.7535 - val_loss: 0.6301 - val_accuracy: 0.7353\n",
      "Epoch 3/20\n",
      "93970/93970 [==============================] - 27s 286us/sample - loss: 0.5435 - accuracy: 0.7742 - val_loss: 0.5936 - val_accuracy: 0.7495\n",
      "Epoch 4/20\n",
      "93970/93970 [==============================] - 27s 286us/sample - loss: 0.5068 - accuracy: 0.7896 - val_loss: 0.5686 - val_accuracy: 0.7697\n",
      "Epoch 5/20\n",
      "93970/93970 [==============================] - 27s 286us/sample - loss: 0.4701 - accuracy: 0.8066 - val_loss: 0.5787 - val_accuracy: 0.7697\n",
      "Epoch 6/20\n",
      "93970/93970 [==============================] - 26s 280us/sample - loss: 0.4334 - accuracy: 0.8224 - val_loss: 0.6046 - val_accuracy: 0.7558\n",
      "Epoch 7/20\n",
      "93970/93970 [==============================] - 26s 275us/sample - loss: 0.3925 - accuracy: 0.8414 - val_loss: 0.6323 - val_accuracy: 0.7600\n",
      "Epoch 8/20\n",
      "93970/93970 [==============================] - 25s 268us/sample - loss: 0.3535 - accuracy: 0.8582 - val_loss: 0.6678 - val_accuracy: 0.7400\n",
      "Epoch 9/20\n",
      "93970/93970 [==============================] - 25s 262us/sample - loss: 0.3149 - accuracy: 0.8754 - val_loss: 0.7440 - val_accuracy: 0.7493\n",
      "##################################################\n",
      "Model 1, iteration 8\n",
      "Train on 93970 samples, validate on 4946 samples\n",
      "Epoch 1/20\n",
      "93970/93970 [==============================] - 27s 286us/sample - loss: 0.7357 - accuracy: 0.6897 - val_loss: 0.7652 - val_accuracy: 0.6741\n",
      "Epoch 2/20\n",
      "93970/93970 [==============================] - 24s 252us/sample - loss: 0.5935 - accuracy: 0.7520 - val_loss: 0.6010 - val_accuracy: 0.7436\n",
      "Epoch 3/20\n",
      "93970/93970 [==============================] - 24s 252us/sample - loss: 0.5454 - accuracy: 0.7735 - val_loss: 0.6077 - val_accuracy: 0.7517\n",
      "Epoch 4/20\n",
      "93970/93970 [==============================] - 24s 259us/sample - loss: 0.5094 - accuracy: 0.7889 - val_loss: 0.5865 - val_accuracy: 0.7550\n",
      "Epoch 5/20\n",
      "93970/93970 [==============================] - 24s 257us/sample - loss: 0.4755 - accuracy: 0.8048 - val_loss: 0.5872 - val_accuracy: 0.7588\n",
      "Epoch 6/20\n",
      "93970/93970 [==============================] - 24s 255us/sample - loss: 0.4393 - accuracy: 0.8204 - val_loss: 0.5948 - val_accuracy: 0.7521\n",
      "Epoch 7/20\n",
      "93970/93970 [==============================] - 24s 253us/sample - loss: 0.3968 - accuracy: 0.8387 - val_loss: 0.8931 - val_accuracy: 0.7188\n",
      "Epoch 8/20\n",
      "93970/93970 [==============================] - 24s 252us/sample - loss: 0.3574 - accuracy: 0.8551 - val_loss: 0.6815 - val_accuracy: 0.7564\n",
      "Epoch 9/20\n",
      "93970/93970 [==============================] - 25s 263us/sample - loss: 0.3169 - accuracy: 0.8725 - val_loss: 0.7328 - val_accuracy: 0.7535\n",
      "##################################################\n",
      "Model 1, iteration 9\n",
      "Train on 93970 samples, validate on 4946 samples\n",
      "Epoch 1/20\n",
      "93970/93970 [==============================] - 26s 277us/sample - loss: 0.7293 - accuracy: 0.6935 - val_loss: 0.6335 - val_accuracy: 0.7309\n",
      "Epoch 2/20\n",
      "93970/93970 [==============================] - 26s 276us/sample - loss: 0.5964 - accuracy: 0.7523 - val_loss: 0.5912 - val_accuracy: 0.7515\n",
      "Epoch 3/20\n",
      "93970/93970 [==============================] - 26s 281us/sample - loss: 0.5443 - accuracy: 0.7734 - val_loss: 0.5887 - val_accuracy: 0.7552\n",
      "Epoch 4/20\n",
      "93970/93970 [==============================] - 26s 274us/sample - loss: 0.5074 - accuracy: 0.7896 - val_loss: 0.6559 - val_accuracy: 0.7273\n",
      "Epoch 5/20\n",
      "93970/93970 [==============================] - 26s 280us/sample - loss: 0.4735 - accuracy: 0.8052 - val_loss: 0.5736 - val_accuracy: 0.7669\n",
      "Epoch 6/20\n",
      "93970/93970 [==============================] - 25s 265us/sample - loss: 0.4364 - accuracy: 0.8208 - val_loss: 0.5892 - val_accuracy: 0.7645\n",
      "Epoch 7/20\n",
      "93970/93970 [==============================] - 24s 261us/sample - loss: 0.3941 - accuracy: 0.8388 - val_loss: 0.6277 - val_accuracy: 0.7624\n",
      "Epoch 8/20\n",
      "93970/93970 [==============================] - 25s 261us/sample - loss: 0.3603 - accuracy: 0.8541 - val_loss: 0.7166 - val_accuracy: 0.7519\n",
      "Epoch 9/20\n",
      "93970/93970 [==============================] - 24s 257us/sample - loss: 0.3202 - accuracy: 0.8717 - val_loss: 0.7529 - val_accuracy: 0.7501\n",
      "Epoch 10/20\n",
      "93970/93970 [==============================] - 24s 254us/sample - loss: 0.2797 - accuracy: 0.8889 - val_loss: 0.8095 - val_accuracy: 0.7497\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    \n",
    "    X_train_tmp, X_val_tmp, y_train_tmp, y_val_tmp = train_test_split(\n",
    "        np.concatenate((X_train, X_train_meta), axis=1), \n",
    "        y_train, \n",
    "        test_size=0.05)\n",
    "    \n",
    "    X_train_tmp, X_train_tmp_meta = X_train_tmp[:,:100], X_train_tmp[:,100:]\n",
    "    X_val_tmp, X_val_tmp_meta = X_val_tmp[:,:100], X_val_tmp[:,100:]\n",
    "\n",
    "    \n",
    "    model = model_1.get_model(embedding_matrix, maxlen, max_features, embed_size, len(features))\n",
    "    adam = tf.keras.optimizers.Adam(lr=1e-3)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    \n",
    "    print(\"##################################################\")\n",
    "    print(f'Model 1, iteration {i}')\n",
    "    \n",
    "    callback_earlystop = tf.keras.callbacks.EarlyStopping(patience=5,\n",
    "                                               monitor='val_loss',\n",
    "                                               mode='auto',\n",
    "                                               restore_best_weights=True)\n",
    "    \n",
    "    \n",
    "    model.fit([X_train_tmp, X_train_tmp_meta], y_train_tmp, epochs = 20, batch_size=256,\n",
    "              callbacks=[callback_earlystop], validation_data=([X_val_tmp, X_val_tmp_meta], y_val_tmp))\n",
    "    \n",
    "    y_hat_val = model.predict([X_val, X_val_meta])\n",
    "    y_hat_val.tofile(f'./results/Model_1_{i}_val_cls')\n",
    "    \n",
    "    y_hat_test = model.predict([X_test, X_test_meta])\n",
    "    y_hat_test.tofile(f'./results/Model_1_{i}_test_cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.tofile('./results/y_val_cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-1558420e111c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/ml-nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml-nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "accuracy_score(y_hat_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_hat_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5650.,    0.,    0.,    0.,    0., 1941.,    0.,    0.,    0.,\n",
       "        1011.]),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.argmax(y_hat_val, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7650546384561729"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_hat_val, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_h = np.zeros_like(y_hat_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7760985817251802"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    y_hat_tmp = np.fromfile(f'./results/Model_1_{i}_val_cls', dtype='float32').reshape(-1, 3)\n",
    "    \n",
    "    y_hat_tmp_cat = to_categorical(np.argmax(y_hat_tmp, axis=1))\n",
    "    \n",
    "    y_h = y_h + y_hat_tmp_cat\n",
    "\n",
    "y_h = y_h + np.random.normal(size=y_h.shape)/1e4    \n",
    "\n",
    "accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_h, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_tmp = np.fromfile(f'./results/Model_1_9_val_cls', dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.31444729e-03, 9.85892117e-01, 9.79345012e-03],\n",
       "       [9.71522510e-01, 3.74247832e-03, 2.47350801e-02],\n",
       "       [9.52562451e-01, 3.26307374e-03, 4.41743843e-02],\n",
       "       ...,\n",
       "       [9.87278819e-01, 3.59171361e-04, 1.23619875e-02],\n",
       "       [7.99559474e-01, 6.22830261e-03, 1.94212228e-01],\n",
       "       [9.88657534e-01, 1.29938161e-03, 1.00430893e-02]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_tmp.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.65578233e-05, -8.17504449e-05,  1.13687440e-04],\n",
       "       [ 6.46776612e-05,  8.03397399e-06,  8.62379212e-05],\n",
       "       [-3.61107318e-05,  7.13434988e-05,  2.89199838e-05],\n",
       "       ...,\n",
       "       [ 3.86541977e-05,  7.01420360e-05, -1.48803446e-04],\n",
       "       [ 1.95962411e-04, -1.53673700e-04, -3.05670201e-05],\n",
       "       [ 6.46758876e-05, -2.46153231e-05, -1.85003079e-04]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_tmp = np.fromfile(f'./results/Model_1_0_val_cls', dtype='float32').reshape(-1, 3)\n",
    "np.random.normal(size=y_hat_tmp.shape)/1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8602, 3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45233, 100)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>condition</th>\n",
       "      <th>opinion</th>\n",
       "      <th>opinion_length</th>\n",
       "      <th>capital_counts</th>\n",
       "      <th>special_counts</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>...</th>\n",
       "      <th>oov_paragard</th>\n",
       "      <th>oov_Otezla</th>\n",
       "      <th>oov_iud</th>\n",
       "      <th>oov_Levora</th>\n",
       "      <th>oov_obgyn</th>\n",
       "      <th>oov_Belsomra</th>\n",
       "      <th>oov_cyclen</th>\n",
       "      <th>oov_nuvaring</th>\n",
       "      <th>oov_Minastrin</th>\n",
       "      <th>oov_Invokana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Vitamin B12</td>\n",
       "      <td>Vitamin B12 Deficiency</td>\n",
       "      <td>No after taste at unlike all the others that I...</td>\n",
       "      <td>185.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.027778</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Implanon</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>I have not had any issues with the implanon I ...</td>\n",
       "      <td>766.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.793750</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BuSpar</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>I have been taking Buspar and Celexa and as fa...</td>\n",
       "      <td>715.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4.283582</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Abreva</td>\n",
       "      <td>Herpes Simplex</td>\n",
       "      <td>the only thing that works  completely awesome</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>UPDATE I originally posted on Nov ##th #### th...</td>\n",
       "      <td>507.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>4.430108</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45228</th>\n",
       "      <td>49993</td>\n",
       "      <td>Fluticasone</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>Every time I use Flonase it enhances my sympto...</td>\n",
       "      <td>329.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.238095</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45229</th>\n",
       "      <td>49994</td>\n",
       "      <td>Viibryd</td>\n",
       "      <td>Depression</td>\n",
       "      <td>I had a bad experience with this I felt dizzy ...</td>\n",
       "      <td>221.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.162791</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45230</th>\n",
       "      <td>49995</td>\n",
       "      <td>Acetaminophen / hydrocodone</td>\n",
       "      <td>Pain</td>\n",
       "      <td>These just don t help me at all and they claim...</td>\n",
       "      <td>284.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45231</th>\n",
       "      <td>49996</td>\n",
       "      <td>Minastrin 24 Fe</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>I got on Minastrin because I used to take Loes...</td>\n",
       "      <td>486.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4.662791</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45232</th>\n",
       "      <td>49999</td>\n",
       "      <td>Drysol</td>\n",
       "      <td>0&lt;/span&gt; users found this comment helpful.</td>\n",
       "      <td>I m ## and I have been using Drysol since I wa...</td>\n",
       "      <td>745.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3.973154</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45233 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                         name  \\\n",
       "0          0                  Vitamin B12   \n",
       "1          1                     Implanon   \n",
       "2          2                       BuSpar   \n",
       "3          3                       Abreva   \n",
       "4          4     Buprenorphine / naloxone   \n",
       "...      ...                          ...   \n",
       "45228  49993                  Fluticasone   \n",
       "45229  49994                      Viibryd   \n",
       "45230  49995  Acetaminophen / hydrocodone   \n",
       "45231  49996              Minastrin 24 Fe   \n",
       "45232  49999                       Drysol   \n",
       "\n",
       "                                        condition  \\\n",
       "0                          Vitamin B12 Deficiency   \n",
       "1                                   Birth Control   \n",
       "2                                         Anxiety   \n",
       "3                                  Herpes Simplex   \n",
       "4                               Opiate Dependence   \n",
       "...                                           ...   \n",
       "45228                           Allergic Rhinitis   \n",
       "45229                                  Depression   \n",
       "45230                                        Pain   \n",
       "45231                               Birth Control   \n",
       "45232  0</span> users found this comment helpful.   \n",
       "\n",
       "                                                 opinion  opinion_length  \\\n",
       "0      No after taste at unlike all the others that I...           185.0   \n",
       "1      I have not had any issues with the implanon I ...           766.0   \n",
       "2      I have been taking Buspar and Celexa and as fa...           715.0   \n",
       "3          the only thing that works  completely awesome            49.0   \n",
       "4      UPDATE I originally posted on Nov ##th #### th...           507.0   \n",
       "...                                                  ...             ...   \n",
       "45228  Every time I use Flonase it enhances my sympto...           329.0   \n",
       "45229  I had a bad experience with this I felt dizzy ...           221.0   \n",
       "45230  These just don t help me at all and they claim...           284.0   \n",
       "45231  I got on Minastrin because I used to take Loes...           486.0   \n",
       "45232  I m ## and I have been using Drysol since I wa...           745.0   \n",
       "\n",
       "       capital_counts  special_counts  word_count  unique_word_count  \\\n",
       "0                 4.0             6.0        36.0               27.0   \n",
       "1                17.0            22.0       160.0               99.0   \n",
       "2                22.0            29.0       134.0               96.0   \n",
       "3                 0.0             4.0         7.0                7.0   \n",
       "4                83.0            22.0        93.0               74.0   \n",
       "...               ...             ...         ...                ...   \n",
       "45228            10.0            11.0        63.0               51.0   \n",
       "45229             5.0            11.0        43.0               36.0   \n",
       "45230             6.0             7.0        57.0               43.0   \n",
       "45231            16.0            22.0        86.0               70.0   \n",
       "45232            21.0            18.0       149.0              101.0   \n",
       "\n",
       "       mean_word_length  ...  oov_paragard  oov_Otezla  oov_iud  oov_Levora  \\\n",
       "0              4.027778  ...         False       False    False       False   \n",
       "1              3.793750  ...         False       False    False       False   \n",
       "2              4.283582  ...         False       False    False       False   \n",
       "3              6.000000  ...         False       False    False       False   \n",
       "4              4.430108  ...         False       False    False       False   \n",
       "...                 ...  ...           ...         ...      ...         ...   \n",
       "45228          4.238095  ...         False       False    False       False   \n",
       "45229          4.162791  ...         False       False    False       False   \n",
       "45230          4.000000  ...         False       False    False       False   \n",
       "45231          4.662791  ...         False       False    False       False   \n",
       "45232          3.973154  ...         False       False    False       False   \n",
       "\n",
       "       oov_obgyn  oov_Belsomra  oov_cyclen  oov_nuvaring  oov_Minastrin  \\\n",
       "0          False         False       False         False          False   \n",
       "1          False         False       False         False          False   \n",
       "2          False         False       False         False          False   \n",
       "3          False         False       False         False          False   \n",
       "4          False         False       False         False          False   \n",
       "...          ...           ...         ...           ...            ...   \n",
       "45228      False         False       False         False          False   \n",
       "45229      False         False       False         False          False   \n",
       "45230      False         False       False         False          False   \n",
       "45231      False         False       False         False           True   \n",
       "45232      False         False       False         False          False   \n",
       "\n",
       "       oov_Invokana  \n",
       "0             False  \n",
       "1             False  \n",
       "2             False  \n",
       "3             False  \n",
       "4             False  \n",
       "...             ...  \n",
       "45228         False  \n",
       "45229         False  \n",
       "45230         False  \n",
       "45231         False  \n",
       "45232         False  \n",
       "\n",
       "[45233 rows x 111 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-nlp)",
   "language": "python",
   "name": "ml-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
